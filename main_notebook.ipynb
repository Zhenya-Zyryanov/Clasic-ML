{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-31T10:15:25.833027Z",
     "start_time": "2025-08-31T10:15:13.733106Z"
    }
   },
   "source": [
    "from Softmax_model.Softmax import SoftmaxClassifier\n",
    "from Decision_Trees_model.decision_trees import DecisionTree_classification\n",
    "from Decision_Trees_model.decision_trees import RandomForest_classification\n",
    "from Decision_Trees_model.decision_trees import GBDT_with_sklearn_classification\n",
    "from Neural_Network_model.MLP_network import MLP_network\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T08:58:10.803755Z",
     "start_time": "2025-08-31T08:03:24.463232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('Datasets/har_train.csv')\n",
    "test = pd.read_csv('Datasets/har_test.csv')\n",
    "\n",
    "x_train = train.drop(['Activity', 'subject'], axis=1).to_numpy()\n",
    "y_train = train['Activity'].to_numpy()\n",
    "\n",
    "x_test = test.drop(['Activity', 'subject'], axis=1).to_numpy()\n",
    "y_test = test['Activity'].to_numpy()\n",
    "\n",
    "print(\"========== Dataset: Human Activity Recognition ==========\")\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "print(\"Softmax selfmade:\")\n",
    "softmax_file = \"softmax_model_har.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = SoftmaxClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_iter=100000,\n",
    "        eps=1e-4,\n",
    "        lambda_reg=0.05,\n",
    "        use_pca=True,\n",
    "        n_components=0.95\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_model_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nSoftmax library:\")\n",
    "softmax_file = \"softmax_sklearn_har.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = LogisticRegression(solver=\"saga\", max_iter=10000, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_sklearn_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree selfmade:\")\n",
    "tree_file = \"decision_tree_model_har.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTree_classification(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_model_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree library:\")\n",
    "tree_file = \"decision_tree_sklearn_har.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTreeClassifier(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_sklearn_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest selfmade:\")\n",
    "forest_file = \"random_forest_model_har.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForest_classification(max_depth=8, n_trees=50, method=\"sqrt\")\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_model_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest library:\")\n",
    "forest_file = \"random_forest_sklearn_har.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForestClassifier(max_depth=8, n_estimators=50, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_sklearn_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees selfmade:\")\n",
    "gbdt_file = \"gbdt_model_har.joblib\"\n",
    "\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = GBDT_with_sklearn_classification(n_estimators=50, max_depth=8, learning_rate=0.1,\n",
    "                                         subsample=0.85, min_samples_split=20)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/gbdt_model_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees library:\")\n",
    "gbdt_file = \"gbdt_xgbc_har.joblib\"\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = XGBClassifier(n_estimators=50, max_depth=8)\n",
    "    model.fit(x_train, y_train_enc, eval_set=[(x_train, y_train_enc)], verbose=False)\n",
    "    dump(model, \"Saved models/gbdt_xgbc_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP selfmade:\")\n",
    "mpl_file = \"mlp_model_har.joblib\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLP_network(lambda_reg=0.001)\n",
    "    model.fit(x_train_scaled, y_train_enc, verbose=True)\n",
    "    dump(model, \"Saved models/mlp_model_har.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred_train = model.predict(x_train_scaled)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP library:\")\n",
    "mpl_file = \"mlp_sklearn_har.joblib\"\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128, 64, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(x_train_scaled, y_train_enc)\n",
    "    dump(model, \"Saved models/mlp_sklearn_har.joblib\")\n",
    "\n",
    "y_pred_enc = model.predict(x_test_scaled)\n",
    "y_pred_train_enc = model.predict(x_train_scaled)\n",
    "y_pred = le.inverse_transform(y_pred_enc)\n",
    "y_pred_train = le.inverse_transform(y_pred_train_enc)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")"
   ],
   "id": "369fc97e4c9ab39e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Dataset: Human Activity Recognition ==========\n",
      "Softmax selfmade:\n",
      "Обучение модели:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2650/100000 [00:09<05:55, 273.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.9345096708517137\n",
      "Accuracy on train: 0.9639553862894451\n",
      "Confusion matrix: \n",
      "[[530   0   7   0   0   0]\n",
      " [  1 428  59   0   0   3]\n",
      " [  0  38 494   0   0   0]\n",
      " [  0   0   0 491   5   0]\n",
      " [  0   0   0  16 369  35]\n",
      " [  0   0   1  25   3 442]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      0.99      0.99       537\n",
      "           SITTING       0.92      0.87      0.89       491\n",
      "          STANDING       0.88      0.93      0.90       532\n",
      "           WALKING       0.92      0.99      0.96       496\n",
      "WALKING_DOWNSTAIRS       0.98      0.88      0.93       420\n",
      "  WALKING_UPSTAIRS       0.92      0.94      0.93       471\n",
      "\n",
      "          accuracy                           0.93      2947\n",
      "         macro avg       0.94      0.93      0.93      2947\n",
      "      weighted avg       0.94      0.93      0.93      2947\n",
      "\n",
      "\n",
      "Softmax library:\n",
      "Accuracy on test: 0.9609772650152698\n",
      "Accuracy on train: 0.9925190424374319\n",
      "Confusion matrix: \n",
      "[[537   0   0   0   0   0]\n",
      " [  0 432  56   0   0   3]\n",
      " [  0  11 520   1   0   0]\n",
      " [  0   0   0 493   3   0]\n",
      " [  0   0   0   3 405  12]\n",
      " [  0   0   0  25   1 445]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.98      0.88      0.93       491\n",
      "          STANDING       0.90      0.98      0.94       532\n",
      "           WALKING       0.94      0.99      0.97       496\n",
      "WALKING_DOWNSTAIRS       0.99      0.96      0.98       420\n",
      "  WALKING_UPSTAIRS       0.97      0.94      0.96       471\n",
      "\n",
      "          accuracy                           0.96      2947\n",
      "         macro avg       0.96      0.96      0.96      2947\n",
      "      weighted avg       0.96      0.96      0.96      2947\n",
      "\n",
      "\n",
      "Decision Tree selfmade:\n",
      "Accuracy on test: 0.8554462164913471\n",
      "Accuracy on train: 0.9912948857453754\n",
      "Confusion matrix: \n",
      "[[525  12   0   0   0   0]\n",
      " [  2 366 123   0   0   0]\n",
      " [  0  75 453   2   0   2]\n",
      " [  0   0   0 451  16  29]\n",
      " [  0   0   0  14 353  53]\n",
      " [  3   0   0  55  40 373]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       0.99      0.98      0.98       537\n",
      "           SITTING       0.81      0.75      0.78       491\n",
      "          STANDING       0.79      0.85      0.82       532\n",
      "           WALKING       0.86      0.91      0.89       496\n",
      "WALKING_DOWNSTAIRS       0.86      0.84      0.85       420\n",
      "  WALKING_UPSTAIRS       0.82      0.79      0.80       471\n",
      "\n",
      "          accuracy                           0.86      2947\n",
      "         macro avg       0.85      0.85      0.85      2947\n",
      "      weighted avg       0.86      0.86      0.86      2947\n",
      "\n",
      "\n",
      "Decision Tree library:\n",
      "Accuracy on test: 0.8649474041398032\n",
      "Accuracy on train: 0.9995919477693145\n",
      "Confusion matrix: \n",
      "[[537   0   0   0   0   0]\n",
      " [  0 379 112   0   0   0]\n",
      " [  0  76 456   0   0   0]\n",
      " [  0   0   0 456  23  17]\n",
      " [  0   0   0  16 355  49]\n",
      " [  0   0   0  76  29 366]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.83      0.77      0.80       491\n",
      "          STANDING       0.80      0.86      0.83       532\n",
      "           WALKING       0.83      0.92      0.87       496\n",
      "WALKING_DOWNSTAIRS       0.87      0.85      0.86       420\n",
      "  WALKING_UPSTAIRS       0.85      0.78      0.81       471\n",
      "\n",
      "          accuracy                           0.86      2947\n",
      "         macro avg       0.86      0.86      0.86      2947\n",
      "      weighted avg       0.87      0.86      0.86      2947\n",
      "\n",
      "\n",
      "Random Forest selfmade:\n",
      "Обучение модели:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [26:31<00:00, 31.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.9053274516457415\n",
      "Accuracy on train: 0.985310119695321\n",
      "Confusion matrix: \n",
      "[[523   7   7   0   0   0]\n",
      " [  8 367 115   0   0   1]\n",
      " [  0   6 526   0   0   0]\n",
      " [  0   0   0 489   6   1]\n",
      " [  0   0   0  33 333  54]\n",
      " [  0   0   0  34   7 430]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       0.98      0.97      0.98       537\n",
      "           SITTING       0.97      0.75      0.84       491\n",
      "          STANDING       0.81      0.99      0.89       532\n",
      "           WALKING       0.88      0.99      0.93       496\n",
      "WALKING_DOWNSTAIRS       0.96      0.79      0.87       420\n",
      "  WALKING_UPSTAIRS       0.88      0.91      0.90       471\n",
      "\n",
      "          accuracy                           0.91      2947\n",
      "         macro avg       0.91      0.90      0.90      2947\n",
      "      weighted avg       0.91      0.91      0.90      2947\n",
      "\n",
      "\n",
      "Random Forest library:\n",
      "Accuracy on test: 0.9144893111638955\n",
      "Accuracy on train: 0.9863982589771491\n",
      "Confusion matrix: \n",
      "[[537   0   0   0   0   0]\n",
      " [  0 429  62   0   0   0]\n",
      " [  0  44 488   0   0   0]\n",
      " [  0   0   0 481   7   8]\n",
      " [  0   0   0  25 346  49]\n",
      " [  0   0   0  50   7 414]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.91      0.87      0.89       491\n",
      "          STANDING       0.89      0.92      0.90       532\n",
      "           WALKING       0.87      0.97      0.91       496\n",
      "WALKING_DOWNSTAIRS       0.96      0.82      0.89       420\n",
      "  WALKING_UPSTAIRS       0.88      0.88      0.88       471\n",
      "\n",
      "          accuracy                           0.91      2947\n",
      "         macro avg       0.92      0.91      0.91      2947\n",
      "      weighted avg       0.92      0.91      0.91      2947\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение GBDT: 100%|██████████| 50/50 [14:52<00:00, 17.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.9019341703427214\n",
      "Accuracy on train: 0.999455930359086\n",
      "Confusion matrix: \n",
      "[[537   0   0   0   0   0]\n",
      " [  0 392  96   0   0   3]\n",
      " [  0  56 475   0   0   1]\n",
      " [  1   2   0 462  13  18]\n",
      " [  8   0   1  15 371  25]\n",
      " [  2   1   0  40   7 421]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       0.98      1.00      0.99       537\n",
      "           SITTING       0.87      0.80      0.83       491\n",
      "          STANDING       0.83      0.89      0.86       532\n",
      "           WALKING       0.89      0.93      0.91       496\n",
      "WALKING_DOWNSTAIRS       0.95      0.88      0.91       420\n",
      "  WALKING_UPSTAIRS       0.90      0.89      0.90       471\n",
      "\n",
      "          accuracy                           0.90      2947\n",
      "         macro avg       0.90      0.90      0.90      2947\n",
      "      weighted avg       0.90      0.90      0.90      2947\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees library:\n",
      "Accuracy on test: 0.9280624363759755\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[537   0   0   0   0   0]\n",
      " [  0 406  82   0   0   3]\n",
      " [  0  35 497   0   0   0]\n",
      " [  0   0   0 483  11   2]\n",
      " [  0   0   0   9 384  27]\n",
      " [  0   0   0  35   8 428]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.92      0.83      0.87       491\n",
      "          STANDING       0.86      0.93      0.89       532\n",
      "           WALKING       0.92      0.97      0.94       496\n",
      "WALKING_DOWNSTAIRS       0.95      0.91      0.93       420\n",
      "  WALKING_UPSTAIRS       0.93      0.91      0.92       471\n",
      "\n",
      "          accuracy                           0.93      2947\n",
      "         macro avg       0.93      0.93      0.93      2947\n",
      "      weighted avg       0.93      0.93      0.93      2947\n",
      "\n",
      "\n",
      "MLP selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0, loss=2.663143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  20%|██        | 202/1000 [00:24<01:37,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 200, loss=0.709642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  40%|████      | 402/1000 [00:47<01:04,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 400, loss=0.605765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  60%|██████    | 602/1000 [01:12<00:43,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 600, loss=0.567273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  70%|███████   | 702/1000 [01:23<00:35,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Остановка на 702 эпохе, change=9.98e-05<eps=0.0001\n",
      "Accuracy on test: 0.9260264675941635\n",
      "Accuracy on train: 0.9793253536452666\n",
      "Confusion matrix: \n",
      "[[535   0   1   0   0   1]\n",
      " [  1 425  62   0   0   3]\n",
      " [  0  36 496   0   0   0]\n",
      " [  0   0   0 475  10  11]\n",
      " [  0   0   0  26 356  38]\n",
      " [  0   0   0  24   5 442]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.92      0.87      0.89       491\n",
      "          STANDING       0.89      0.93      0.91       532\n",
      "           WALKING       0.90      0.96      0.93       496\n",
      "WALKING_DOWNSTAIRS       0.96      0.85      0.90       420\n",
      "  WALKING_UPSTAIRS       0.89      0.94      0.92       471\n",
      "\n",
      "          accuracy                           0.93      2947\n",
      "         macro avg       0.93      0.92      0.92      2947\n",
      "      weighted avg       0.93      0.93      0.93      2947\n",
      "\n",
      "\n",
      "MLP library:\n",
      "Accuracy on test: 0.9436715303698676\n",
      "Accuracy on train: 0.9978237214363439\n",
      "Confusion matrix: \n",
      "[[522   1  13   1   0   0]\n",
      " [  0 425  66   0   0   0]\n",
      " [  0  22 507   3   0   0]\n",
      " [  0   0   0 489   5   2]\n",
      " [  0   0   0  15 384  21]\n",
      " [  0   0   1  12   4 454]]\n",
      "Classification report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      0.97      0.99       537\n",
      "           SITTING       0.95      0.87      0.91       491\n",
      "          STANDING       0.86      0.95      0.91       532\n",
      "           WALKING       0.94      0.99      0.96       496\n",
      "WALKING_DOWNSTAIRS       0.98      0.91      0.94       420\n",
      "  WALKING_UPSTAIRS       0.95      0.96      0.96       471\n",
      "\n",
      "          accuracy                           0.94      2947\n",
      "         macro avg       0.95      0.94      0.94      2947\n",
      "      weighted avg       0.95      0.94      0.94      2947\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T08:58:17.918367Z",
     "start_time": "2025-08-31T08:58:10.924283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_wine = load_wine()\n",
    "wine_df = pd.DataFrame(data_wine.data, columns=data_wine.feature_names)\n",
    "wine_df['target'] = data_wine.target_names[data_wine.target]\n",
    "\n",
    "wine_map = {'class_0': 'Производитель 1', 'class_1': 'Производитель 2', 'class_2': 'Производитель 3'}\n",
    "wine_df['target'] = wine_df['target'].map(wine_map)\n",
    "\n",
    "x_wine = wine_df.drop(['target'], axis=1).copy().to_numpy()\n",
    "y_wine = wine_df['target'].copy().to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_wine, y_wine, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"========== Dataset: Wine manufacturer ==========\")\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "print(\"Softmax selfmade:\")\n",
    "softmax_file = \"softmax_model_wine.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = SoftmaxClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_iter=100000,\n",
    "        eps=1e-4,\n",
    "        lambda_reg=0.05,\n",
    "        use_pca=True,\n",
    "        n_components=0.95\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_model_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nSoftmax library:\")\n",
    "softmax_file = \"softmax_sklearn_wine.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = LogisticRegression(solver=\"saga\", max_iter=10000, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_sklearn_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree selfmade:\")\n",
    "tree_file = \"decision_tree_model_wine.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTree_classification(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_model_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree library:\")\n",
    "tree_file = \"decision_tree_sklearn_wine.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTreeClassifier(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_sklearn_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest selfmade:\")\n",
    "forest_file = \"random_forest_model_wine.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForest_classification(max_depth=8, n_trees=50, method=\"sqrt\")\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_model_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest library:\")\n",
    "forest_file = \"random_forest_sklearn_wine.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForestClassifier(max_depth=8, n_estimators=50, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_sklearn_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees selfmade:\")\n",
    "gbdt_file = \"gbdt_model_wine.joblib\"\n",
    "\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = GBDT_with_sklearn_classification(n_estimators=50, max_depth=8, learning_rate=0.1,\n",
    "                                         subsample=0.85, min_samples_split=20)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/gbdt_model_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees library:\")\n",
    "gbdt_file = \"gbdt_xgbc_wine.joblib\"\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = XGBClassifier(n_estimators=50, max_depth=8)\n",
    "    model.fit(x_train, y_train_enc, eval_set=[(x_train, y_train_enc)], verbose=False)\n",
    "    dump(model, \"Saved models/gbdt_xgbc_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP selfmade:\")\n",
    "mpl_file = \"mlp_model_wine.joblib\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLP_network(lambda_reg=0.001)\n",
    "    model.fit(x_train_scaled, y_train_enc, verbose=True)\n",
    "    dump(model, \"Saved models/mlp_model_wine.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred_train = model.predict(x_train_scaled)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP library:\")\n",
    "mpl_file = \"mlp_sklearn_wine.joblib\"\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128, 64, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(x_train_scaled, y_train_enc)\n",
    "    dump(model, \"Saved models/mlp_sklearn_wine.joblib\")\n",
    "\n",
    "y_pred_enc = model.predict(x_test_scaled)\n",
    "y_pred_train_enc = model.predict(x_train_scaled)\n",
    "y_pred = le.inverse_transform(y_pred_enc)\n",
    "y_pred_train = le.inverse_transform(y_pred_train_enc)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")"
   ],
   "id": "22d8520d322e57ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Dataset: Wine manufacturer ==========\n",
      "Softmax selfmade:\n",
      "Обучение модели:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 959/100000 [00:00<00:05, 17584.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 1.0\n",
      "Accuracy on train: 0.9919354838709677\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 14]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       1.00      1.00      1.00        19\n",
      "Производитель 2       1.00      1.00      1.00        21\n",
      "Производитель 3       1.00      1.00      1.00        14\n",
      "\n",
      "       accuracy                           1.00        54\n",
      "      macro avg       1.00      1.00      1.00        54\n",
      "   weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "\n",
      "Softmax library:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.9814814814814815\n",
      "Accuracy on train: 0.9193548387096774\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 21  0]\n",
      " [ 1  0 13]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       0.95      1.00      0.97        19\n",
      "Производитель 2       1.00      1.00      1.00        21\n",
      "Производитель 3       1.00      0.93      0.96        14\n",
      "\n",
      "       accuracy                           0.98        54\n",
      "      macro avg       0.98      0.98      0.98        54\n",
      "   weighted avg       0.98      0.98      0.98        54\n",
      "\n",
      "\n",
      "Decision Tree selfmade:\n",
      "Accuracy on test: 0.8333333333333334\n",
      "Accuracy on train: 0.9758064516129032\n",
      "Confusion matrix: \n",
      "[[17  2  0]\n",
      " [ 2 18  1]\n",
      " [ 2  2 10]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       0.81      0.89      0.85        19\n",
      "Производитель 2       0.82      0.86      0.84        21\n",
      "Производитель 3       0.91      0.71      0.80        14\n",
      "\n",
      "       accuracy                           0.83        54\n",
      "      macro avg       0.85      0.82      0.83        54\n",
      "   weighted avg       0.84      0.83      0.83        54\n",
      "\n",
      "\n",
      "Decision Tree library:\n",
      "Accuracy on test: 0.9444444444444444\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[17  2  0]\n",
      " [ 0 21  0]\n",
      " [ 1  0 13]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       0.94      0.89      0.92        19\n",
      "Производитель 2       0.91      1.00      0.95        21\n",
      "Производитель 3       1.00      0.93      0.96        14\n",
      "\n",
      "       accuracy                           0.94        54\n",
      "      macro avg       0.95      0.94      0.95        54\n",
      "   weighted avg       0.95      0.94      0.94        54\n",
      "\n",
      "\n",
      "Random Forest selfmade:\n",
      "Обучение модели:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.9814814814814815\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 20  1]\n",
      " [ 0  0 14]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       1.00      1.00      1.00        19\n",
      "Производитель 2       1.00      0.95      0.98        21\n",
      "Производитель 3       0.93      1.00      0.97        14\n",
      "\n",
      "       accuracy                           0.98        54\n",
      "      macro avg       0.98      0.98      0.98        54\n",
      "   weighted avg       0.98      0.98      0.98        54\n",
      "\n",
      "\n",
      "Random Forest library:\n",
      "Accuracy on test: 1.0\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 14]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       1.00      1.00      1.00        19\n",
      "Производитель 2       1.00      1.00      1.00        21\n",
      "Производитель 3       1.00      1.00      1.00        14\n",
      "\n",
      "       accuracy                           1.00        54\n",
      "      macro avg       1.00      1.00      1.00        54\n",
      "   weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение GBDT: 100%|██████████| 50/50 [00:00<00:00, 257.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.9814814814814815\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[18  1  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 14]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       1.00      0.95      0.97        19\n",
      "Производитель 2       0.95      1.00      0.98        21\n",
      "Производитель 3       1.00      1.00      1.00        14\n",
      "\n",
      "       accuracy                           0.98        54\n",
      "      macro avg       0.98      0.98      0.98        54\n",
      "   weighted avg       0.98      0.98      0.98        54\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees library:\n",
      "Accuracy on test: 0.9629629629629629\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 1 20  0]\n",
      " [ 0  1 13]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       0.95      1.00      0.97        19\n",
      "Производитель 2       0.95      0.95      0.95        21\n",
      "Производитель 3       1.00      0.93      0.96        14\n",
      "\n",
      "       accuracy                           0.96        54\n",
      "      macro avg       0.97      0.96      0.96        54\n",
      "   weighted avg       0.96      0.96      0.96        54\n",
      "\n",
      "\n",
      "MLP selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:   5%|▍         | 46/1000 [00:00<00:02, 457.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0, loss=2.116121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  21%|██        | 207/1000 [00:00<00:01, 402.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 200, loss=0.503631\n",
      "Остановка на 207 эпохе, change=9.91e-05<eps=0.0001\n",
      "Accuracy on test: 0.9629629629629629\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 2 19  0]\n",
      " [ 0  0 14]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       0.90      1.00      0.95        19\n",
      "Производитель 2       1.00      0.90      0.95        21\n",
      "Производитель 3       1.00      1.00      1.00        14\n",
      "\n",
      "       accuracy                           0.96        54\n",
      "      macro avg       0.97      0.97      0.97        54\n",
      "   weighted avg       0.97      0.96      0.96        54\n",
      "\n",
      "\n",
      "MLP library:\n",
      "Accuracy on test: 0.9444444444444444\n",
      "Accuracy on train: 0.9919354838709677\n",
      "Confusion matrix: \n",
      "[[17  2  0]\n",
      " [ 0 21  0]\n",
      " [ 1  0 13]]\n",
      "Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Производитель 1       0.94      0.89      0.92        19\n",
      "Производитель 2       0.91      1.00      0.95        21\n",
      "Производитель 3       1.00      0.93      0.96        14\n",
      "\n",
      "       accuracy                           0.94        54\n",
      "      macro avg       0.95      0.94      0.95        54\n",
      "   weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T08:58:21.158922Z",
     "start_time": "2025-08-31T08:58:17.963969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_iris = load_iris()\n",
    "iris_df = pd.DataFrame(data_iris.data, columns=data_iris.feature_names)\n",
    "iris_df['target'] = data_iris.target_names[data_iris.target]\n",
    "\n",
    "x_iris = iris_df.drop(['target'], axis=1).copy().to_numpy()\n",
    "y_iris = iris_df['target'].copy().to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_iris, y_iris, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"========== Dataset: Iris type ==========\")\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "print(\"Softmax selfmade:\")\n",
    "softmax_file = \"softmax_model_iris.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = SoftmaxClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_iter=100000,\n",
    "        eps=1e-4,\n",
    "        lambda_reg=0.05,\n",
    "        use_pca=True,\n",
    "        n_components=0.95\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_model_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nSoftmax library:\")\n",
    "softmax_file = \"softmax_sklearn_iris.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = LogisticRegression(solver=\"saga\", max_iter=10000, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_sklearn_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree selfmade:\")\n",
    "tree_file = \"decision_tree_model_iris.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTree_classification(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_model_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree library:\")\n",
    "tree_file = \"decision_tree_sklearn_iris.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTreeClassifier(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_sklearn_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest selfmade:\")\n",
    "forest_file = \"random_forest_model_iris.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForest_classification(max_depth=8, n_trees=50, method=\"sqrt\")\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_model_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest library:\")\n",
    "forest_file = \"random_forest_sklearn_iris.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForestClassifier(max_depth=8, n_estimators=50, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_sklearn_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees selfmade:\")\n",
    "gbdt_file = \"gbdt_model_iris.joblib\"\n",
    "\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = GBDT_with_sklearn_classification(n_estimators=50, max_depth=8, learning_rate=0.1,\n",
    "                                         subsample=0.85, min_samples_split=20)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/gbdt_model_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees library:\")\n",
    "gbdt_file = \"gbdt_xgbc_iris.joblib\"\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = XGBClassifier(n_estimators=50, max_depth=8)\n",
    "    model.fit(x_train, y_train_enc, eval_set=[(x_train, y_train_enc)], verbose=False)\n",
    "    dump(model, \"Saved models/gbdt_xgbc_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP selfmade:\")\n",
    "mpl_file = \"mlp_model_iris.joblib\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLP_network(lambda_reg=0.001)\n",
    "    model.fit(x_train_scaled, y_train_enc, verbose=True)\n",
    "    dump(model, \"Saved models/mlp_model_iris.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred_train = model.predict(x_train_scaled)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP library:\")\n",
    "mpl_file = \"mlp_sklearn_iris.joblib\"\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128, 64, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(x_train_scaled, y_train_enc)\n",
    "    dump(model, \"Saved models/mlp_sklearn_iris.joblib\")\n",
    "\n",
    "y_pred_enc = model.predict(x_test_scaled)\n",
    "y_pred_train_enc = model.predict(x_train_scaled)\n",
    "y_pred = le.inverse_transform(y_pred_enc)\n",
    "y_pred_train = le.inverse_transform(y_pred_train_enc)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")"
   ],
   "id": "ba3e067704f524d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Dataset: Iris type ==========\n",
      "Softmax selfmade:\n",
      "Обучение модели:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 650/100000 [00:00<00:05, 19215.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.8666666666666667\n",
      "Accuracy on train: 0.8761904761904762\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0  8  5]\n",
      " [ 0  1 12]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       0.89      0.62      0.73        13\n",
      "   virginica       0.71      0.92      0.80        13\n",
      "\n",
      "    accuracy                           0.87        45\n",
      "   macro avg       0.86      0.85      0.84        45\n",
      "weighted avg       0.88      0.87      0.86        45\n",
      "\n",
      "\n",
      "Softmax library:\n",
      "Accuracy on test: 1.0\n",
      "Accuracy on train: 0.9714285714285714\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "Decision Tree selfmade:\n",
      "Accuracy on test: 0.9555555555555556\n",
      "Accuracy on train: 0.9714285714285714\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.85      0.92        13\n",
      "   virginica       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "\n",
      "Decision Tree library:\n",
      "Accuracy on test: 1.0\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "Random Forest selfmade:\n",
      "Обучение модели:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 1.0\n",
      "Accuracy on train: 0.9619047619047619\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "Random Forest library:\n",
      "Accuracy on test: 1.0\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение GBDT: 100%|██████████| 50/50 [00:00<00:00, 444.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 1.0\n",
      "Accuracy on train: 0.9904761904761905\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees library:\n",
      "Accuracy on test: 1.0\n",
      "Accuracy on train: 1.0\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "MLP selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:   4%|▍         | 39/1000 [00:00<00:02, 381.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0, loss=2.301440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  27%|██▋       | 271/1000 [00:00<00:01, 480.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 200, loss=0.639251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  48%|████▊     | 475/1000 [00:01<00:01, 472.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 400, loss=0.585694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  54%|█████▍    | 539/1000 [00:01<00:01, 455.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Остановка на 539 эпохе, change=9.74e-05<eps=0.0001\n",
      "Accuracy on test: 0.9777777777777777\n",
      "Accuracy on train: 0.9809523809523809\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.92      0.96        13\n",
      "   virginica       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "MLP library:\n",
      "Accuracy on test: 0.8444444444444444\n",
      "Accuracy on train: 0.8761904761904762\n",
      "Confusion matrix: \n",
      "[[19  0  0]\n",
      " [ 0  6  7]\n",
      " [ 0  0 13]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.46      0.63        13\n",
      "   virginica       0.65      1.00      0.79        13\n",
      "\n",
      "    accuracy                           0.84        45\n",
      "   macro avg       0.88      0.82      0.81        45\n",
      "weighted avg       0.90      0.84      0.83        45\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T08:58:22.652013Z",
     "start_time": "2025-08-31T08:58:21.172308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "credit_train_df = pd.read_csv(\"Datasets/credit_cleaned_train.csv\", low_memory=False)\n",
    "credit_train_df = credit_train_df.drop(columns=['ID', 'Customer_ID', 'Month', 'Name', 'SSN'], axis=1)\n",
    "\n",
    "print(\"Credit Score distribution:\", np.unique(credit_train_df['Credit_Score'], return_counts=True))\n",
    "\n",
    "type_of_loan_position = credit_train_df.columns.get_loc('Type_of_Loan')\n",
    "\n",
    "loan_map = {'No Data': 'No Data loan', 'not specified': 'not specified loan'}\n",
    "credit_train_df['Type_of_Loan'] = credit_train_df['Type_of_Loan'].map(loan_map)\n",
    "\n",
    "main_loan_types = [\n",
    "    'No Data loan',\n",
    "    'not specified loan',\n",
    "    'credit-builder loan',\n",
    "    'personal loan',\n",
    "    'debt consolidation loan',\n",
    "    'student loan',\n",
    "    'payday loan',\n",
    "    'mortgage loan',\n",
    "    'auto loan',\n",
    "    'home equity loan'\n",
    "]\n",
    "\n",
    "def process_loans(loan_string):\n",
    "    if pd.isna(loan_string):\n",
    "        result = np.zeros(len(main_loan_types))\n",
    "        result[main_loan_types.index('No Data loan')] = 1\n",
    "        return result\n",
    "\n",
    "    loan_str = str(loan_string)\n",
    "    loan_lower = loan_str.lower()\n",
    "\n",
    "    result = np.zeros(len(main_loan_types))\n",
    "\n",
    "    if 'no data loan' in loan_lower:\n",
    "        result[main_loan_types.index('No Data loan')] = 1\n",
    "        return result\n",
    "\n",
    "    loans = [loan.strip() for loan in loan_str.split(',')]\n",
    "\n",
    "    for loan in loans:\n",
    "        loan_lower = loan.lower()\n",
    "        found = False\n",
    "\n",
    "        for i, loan_type in enumerate(main_loan_types[2:]):\n",
    "            if loan_type in loan_lower:\n",
    "                result[i+2] += 1\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "loan_vectors = credit_train_df['Type_of_Loan'].apply(process_loans)\n",
    "\n",
    "for i, loan_type in enumerate(main_loan_types):\n",
    "    col_name = loan_type.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    credit_train_df[f'has_{col_name}'] = loan_vectors.apply(lambda x: 1 if x[i] > 0 else 0)\n",
    "\n",
    "credit_train_df.drop('Type_of_Loan', axis=1, inplace=True)\n",
    "\n",
    "all_columns = credit_train_df.columns.tolist()\n",
    "\n",
    "new_columns = [col for col in all_columns if col.startswith('has_')]\n",
    "\n",
    "for col in new_columns:\n",
    "    all_columns.remove(col)\n",
    "\n",
    "all_columns = all_columns[:type_of_loan_position] + new_columns + all_columns[type_of_loan_position:]\n",
    "credit_train_df = credit_train_df[all_columns]\n",
    "\n",
    "categorical_columns = ['Occupation', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour']\n",
    "\n",
    "column_positions = {}\n",
    "for col in categorical_columns:\n",
    "    column_positions[col] = credit_train_df.columns.get_loc(col)\n",
    "\n",
    "credit_train_df = pd.get_dummies(credit_train_df, columns=categorical_columns, prefix=categorical_columns)\n",
    "\n",
    "bool_columns = credit_train_df.select_dtypes(include=['bool']).columns\n",
    "credit_train_df[bool_columns] = credit_train_df[bool_columns].astype(int)\n",
    "\n",
    "all_columns = credit_train_df.columns.tolist()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    one_hot_cols = [c for c in all_columns if c.startswith(col + '_')]\n",
    "\n",
    "    for one_hot_col in one_hot_cols:\n",
    "        all_columns.remove(one_hot_col)\n",
    "\n",
    "    position = column_positions[col]\n",
    "    all_columns = all_columns[:position] + one_hot_cols + all_columns[position:]\n",
    "\n",
    "credit_train_df = credit_train_df[all_columns]\n",
    "\n",
    "x_credit = credit_train_df.drop('Credit_Score', axis=1).to_numpy()\n",
    "y_credit = credit_train_df['Credit_Score'].to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_credit, y_credit, test_size=0.3, random_state=42)"
   ],
   "id": "81c2276f666f796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Score distribution: (array(['Good', 'Poor', 'Standard'], dtype=object), array([17828, 28998, 53174]))\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T09:35:04.801721Z",
     "start_time": "2025-08-31T08:58:22.662194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"========== Dataset: Credit Score ==========\")\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "print(\"Softmax selfmade:\")\n",
    "softmax_file = \"softmax_model_credit.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = SoftmaxClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_iter=100000,\n",
    "        eps=1e-4,\n",
    "        lambda_reg=0.05,\n",
    "        use_pca=True,\n",
    "        n_components=0.95\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_model_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nSoftmax library:\")\n",
    "softmax_file = \"softmax_sklearn_credit.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = LogisticRegression(solver=\"saga\", max_iter=10000, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_sklearn_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree selfmade:\")\n",
    "tree_file = \"decision_tree_model_credit.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTree_classification(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_model_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree library:\")\n",
    "tree_file = \"decision_tree_sklearn_credit.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTreeClassifier(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_sklearn_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest selfmade:\")\n",
    "forest_file = \"random_forest_model_credit.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForest_classification(max_depth=8, n_trees=50, method=\"sqrt\")\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_model_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest library:\")\n",
    "forest_file = \"random_forest_sklearn_credit.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForestClassifier(max_depth=8, n_estimators=50, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_sklearn_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees selfmade:\")\n",
    "gbdt_file = \"gbdt_model_credit.joblib\"\n",
    "\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = GBDT_with_sklearn_classification(n_estimators=50, max_depth=8, learning_rate=0.1,\n",
    "                                         subsample=0.85, min_samples_split=20)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/gbdt_model_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees library:\")\n",
    "gbdt_file = \"gbdt_xgbc_credit.joblib\"\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = XGBClassifier(n_estimators=50, max_depth=8)\n",
    "    model.fit(x_train, y_train_enc, eval_set=[(x_train, y_train_enc)], verbose=False)\n",
    "    dump(model, \"Saved models/gbdt_xgbc_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP selfmade:\")\n",
    "mpl_file = \"mlp_model_credit.joblib\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLP_network(lambda_reg=0.001)\n",
    "    model.fit(x_train_scaled, y_train_enc, verbose=True)\n",
    "    dump(model, \"Saved models/mlp_model_credit.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred_train = model.predict(x_train_scaled)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP library:\")\n",
    "mpl_file = \"mlp_sklearn_credit.joblib\"\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128, 64, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(x_train_scaled, y_train_enc)\n",
    "    dump(model, \"Saved models/mlp_sklearn_credit.joblib\")\n",
    "\n",
    "y_pred_enc = model.predict(x_test_scaled)\n",
    "y_pred_train_enc = model.predict(x_train_scaled)\n",
    "y_pred = le.inverse_transform(y_pred_enc)\n",
    "y_pred_train = le.inverse_transform(y_pred_train_enc)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")"
   ],
   "id": "539acb2f1af4719b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Dataset: Credit Score ==========\n",
      "Softmax selfmade:\n",
      "Обучение модели:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 529/100000 [00:08<26:13, 63.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.6382666666666666\n",
      "Accuracy on train: 0.6407857142857143\n",
      "Confusion matrix: \n",
      "[[ 3196    73  2053]\n",
      " [  686  4451  3668]\n",
      " [ 2042  2330 11501]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.54      0.60      0.57      5322\n",
      "        Poor       0.65      0.51      0.57      8805\n",
      "    Standard       0.67      0.72      0.70     15873\n",
      "\n",
      "    accuracy                           0.64     30000\n",
      "   macro avg       0.62      0.61      0.61     30000\n",
      "weighted avg       0.64      0.64      0.64     30000\n",
      "\n",
      "\n",
      "Softmax library:\n",
      "Accuracy on test: 0.5807666666666667\n",
      "Accuracy on train: 0.5821285714285714\n",
      "Confusion matrix: \n",
      "[[  477    80  4765]\n",
      " [   59  3797  4949]\n",
      " [  301  2423 13149]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.57      0.09      0.15      5322\n",
      "        Poor       0.60      0.43      0.50      8805\n",
      "    Standard       0.58      0.83      0.68     15873\n",
      "\n",
      "    accuracy                           0.58     30000\n",
      "   macro avg       0.58      0.45      0.45     30000\n",
      "weighted avg       0.58      0.58      0.53     30000\n",
      "\n",
      "\n",
      "Decision Tree selfmade:\n",
      "Accuracy on test: 0.7439333333333333\n",
      "Accuracy on train: 0.8302428571428572\n",
      "Confusion matrix: \n",
      "[[ 3661   133  1528]\n",
      " [  273  6578  1954]\n",
      " [ 1629  2165 12079]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.66      0.69      0.67      5322\n",
      "        Poor       0.74      0.75      0.74      8805\n",
      "    Standard       0.78      0.76      0.77     15873\n",
      "\n",
      "    accuracy                           0.74     30000\n",
      "   macro avg       0.73      0.73      0.73     30000\n",
      "weighted avg       0.74      0.74      0.74     30000\n",
      "\n",
      "\n",
      "Decision Tree library:\n",
      "Accuracy on test: 0.7350333333333333\n",
      "Accuracy on train: 0.8311857142857143\n",
      "Confusion matrix: \n",
      "[[ 3788   117  1417]\n",
      " [  466  6443  1896]\n",
      " [ 1980  2073 11820]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.61      0.71      0.66      5322\n",
      "        Poor       0.75      0.73      0.74      8805\n",
      "    Standard       0.78      0.74      0.76     15873\n",
      "\n",
      "    accuracy                           0.74     30000\n",
      "   macro avg       0.71      0.73      0.72     30000\n",
      "weighted avg       0.74      0.74      0.74     30000\n",
      "\n",
      "\n",
      "Random Forest selfmade:\n",
      "Обучение модели:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [11:34<00:00, 13.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.6183333333333333\n",
      "Accuracy on train: 0.6297\n",
      "Confusion matrix: \n",
      "[[ 1134    58  4130]\n",
      " [  154  4193  4458]\n",
      " [  605  2045 13223]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.60      0.21      0.31      5322\n",
      "        Poor       0.67      0.48      0.56      8805\n",
      "    Standard       0.61      0.83      0.70     15873\n",
      "\n",
      "    accuracy                           0.62     30000\n",
      "   macro avg       0.62      0.51      0.52     30000\n",
      "weighted avg       0.62      0.62      0.59     30000\n",
      "\n",
      "\n",
      "Random Forest library:\n",
      "Accuracy on test: 0.7057666666666667\n",
      "Accuracy on train: 0.7191428571428572\n",
      "Confusion matrix: \n",
      "[[ 4327    38   957]\n",
      " [  996  5754  2055]\n",
      " [ 2839  1942 11092]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.53      0.81      0.64      5322\n",
      "        Poor       0.74      0.65      0.70      8805\n",
      "    Standard       0.79      0.70      0.74     15873\n",
      "\n",
      "    accuracy                           0.71     30000\n",
      "   macro avg       0.69      0.72      0.69     30000\n",
      "weighted avg       0.73      0.71      0.71     30000\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение GBDT: 100%|██████████| 50/50 [01:35<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.7358\n",
      "Accuracy on train: 0.7603428571428571\n",
      "Confusion matrix: \n",
      "[[ 3709   123  1490]\n",
      " [  481  6120  2204]\n",
      " [ 1776  1852 12245]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.62      0.70      0.66      5322\n",
      "        Poor       0.76      0.70      0.72      8805\n",
      "    Standard       0.77      0.77      0.77     15873\n",
      "\n",
      "    accuracy                           0.74     30000\n",
      "   macro avg       0.72      0.72      0.72     30000\n",
      "weighted avg       0.74      0.74      0.74     30000\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees library:\n",
      "Accuracy on test: 0.7788\n",
      "Accuracy on train: 0.8563142857142857\n",
      "Confusion matrix: \n",
      "[[ 3942    68  1312]\n",
      " [  316  6785  1704]\n",
      " [ 1339  1897 12637]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.70      0.74      0.72      5322\n",
      "        Poor       0.78      0.77      0.77      8805\n",
      "    Standard       0.81      0.80      0.80     15873\n",
      "\n",
      "    accuracy                           0.78     30000\n",
      "   macro avg       0.76      0.77      0.77     30000\n",
      "weighted avg       0.78      0.78      0.78     30000\n",
      "\n",
      "\n",
      "MLP selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0, loss=2.277035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  20%|██        | 200/1000 [02:16<08:35,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 200, loss=1.292917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  40%|████      | 400/1000 [04:27<06:36,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 400, loss=1.248351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  58%|█████▊    | 580/1000 [06:27<04:40,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Остановка на 580 эпохе, change=9.99e-05<eps=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.6540333333333334\n",
      "Accuracy on train: 0.6571\n",
      "Confusion matrix: \n",
      "[[ 3195    69  2058]\n",
      " [  865  4800  3140]\n",
      " [ 2170  2077 11626]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.51      0.60      0.55      5322\n",
      "        Poor       0.69      0.55      0.61      8805\n",
      "    Standard       0.69      0.73      0.71     15873\n",
      "\n",
      "    accuracy                           0.65     30000\n",
      "   macro avg       0.63      0.63      0.62     30000\n",
      "weighted avg       0.66      0.65      0.65     30000\n",
      "\n",
      "\n",
      "MLP library:\n",
      "Accuracy on test: 0.7359333333333333\n",
      "Accuracy on train: 0.8194857142857143\n",
      "Confusion matrix: \n",
      "[[ 3674   101  1547]\n",
      " [  138  6432  2235]\n",
      " [ 1690  2211 11972]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.67      0.69      0.68      5322\n",
      "        Poor       0.74      0.73      0.73      8805\n",
      "    Standard       0.76      0.75      0.76     15873\n",
      "\n",
      "    accuracy                           0.74     30000\n",
      "   macro avg       0.72      0.73      0.72     30000\n",
      "weighted avg       0.74      0.74      0.74     30000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T10:24:14.606661Z",
     "start_time": "2025-08-31T10:16:42.380538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_credit_balanced = pd.read_csv(\"C:/Users/zheny/PycharmProjects/Machine_learning_human_activity/Datasets/credit_test1.csv\")\n",
    "x_credit_synth = df_credit_balanced.drop(['Credit_Score'], axis=1).to_numpy()\n",
    "y_credit_synth = df_credit_balanced['Credit_Score'].to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_credit_synth, y_credit_synth,\n",
    "                                                                                                        test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"========== Dataset: Credit Score synth balanced ==========\")\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "print(\"Softmax selfmade:\")\n",
    "softmax_file = \"softmax_model_credit_synth.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = SoftmaxClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_iter=100000,\n",
    "        eps=1e-4,\n",
    "        lambda_reg=0.05,\n",
    "        use_pca=True,\n",
    "        n_components=0.95\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_model_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nSoftmax library:\")\n",
    "softmax_file = \"softmax_sklearn_credit_synth.joblib\"\n",
    "\n",
    "if softmax_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + softmax_file)\n",
    "else:\n",
    "    model = LogisticRegression(solver=\"saga\", max_iter=10000, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/softmax_sklearn_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree selfmade:\")\n",
    "tree_file = \"decision_tree_model_credit_synth.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTree_classification(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_model_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree library:\")\n",
    "tree_file = \"decision_tree_sklearn_credit_synth.joblib\"\n",
    "\n",
    "if tree_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + tree_file)\n",
    "else:\n",
    "    model = DecisionTreeClassifier(max_depth=16)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/decision_tree_sklearn_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "\"\"\"print(\"\\nRandom Forest selfmade:\")\n",
    "forest_file = \"random_forest_model_credit_synth.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForest_classification(max_depth=8, n_trees=50, method=\"sqrt\")\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_model_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nRandom Forest library:\")\n",
    "forest_file = \"random_forest_sklearn_credit_synth.joblib\"\n",
    "\n",
    "if forest_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + forest_file)\n",
    "else:\n",
    "    model = RandomForestClassifier(max_depth=8, n_estimators=50, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/random_forest_sklearn_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees selfmade:\")\n",
    "gbdt_file = \"gbdt_model_credit_synth.joblib\"\n",
    "\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = GBDT_with_sklearn_classification(n_estimators=50, max_depth=8, learning_rate=0.1,\n",
    "                                         subsample=0.85, min_samples_split=20)\n",
    "    model.fit(x_train, y_train)\n",
    "    dump(model, \"Saved models/gbdt_model_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nGradient Boosting Decision Trees library:\")\n",
    "gbdt_file = \"gbdt_xgbc_credit_synth.joblib\"\n",
    "if gbdt_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + gbdt_file)\n",
    "else:\n",
    "    model = XGBClassifier(n_estimators=50, max_depth=8)\n",
    "    model.fit(x_train, y_train_enc, eval_set=[(x_train, y_train_enc)], verbose=False)\n",
    "    dump(model, \"Saved models/gbdt_xgbc_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP selfmade:\")\n",
    "mpl_file = \"mlp_model_credit_synth.joblib\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLP_network(lambda_reg=0.001)\n",
    "    model.fit(x_train_scaled, y_train_enc, verbose=True)\n",
    "    dump(model, \"Saved models/mlp_model_credit_synth.joblib\")\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred_train = model.predict(x_train_scaled)\n",
    "y_pred_enc = le.inverse_transform(y_pred)\n",
    "y_pred_train_enc = le.inverse_transform(y_pred_train)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred_enc)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train_enc)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred_enc)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred_enc)}\")\n",
    "\n",
    "\n",
    "print(\"\\nMLP library:\")\n",
    "mpl_file = \"mlp_sklearn_credit_synth.joblib\"\n",
    "\n",
    "if mpl_file in os.listdir(\"Saved models\"):\n",
    "    model = load(\"Saved models/\" + mpl_file)\n",
    "else:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128, 64, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(x_train_scaled, y_train_enc)\n",
    "    dump(model, \"Saved models/mlp_sklearn_credit_synth.joblib\")\n",
    "\n",
    "y_pred_enc = model.predict(x_test_scaled)\n",
    "y_pred_train_enc = model.predict(x_train_scaled)\n",
    "y_pred = le.inverse_transform(y_pred_enc)\n",
    "y_pred_train = le.inverse_transform(y_pred_train_enc)\n",
    "print(f\"Accuracy on test: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy on train: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification report: \\n{classification_report(y_test, y_pred)}\")"
   ],
   "id": "c901de2f4bda7af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73000 entries, 0 to 72999\n",
      "Data columns (total 56 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   Unnamed: 0                                          73000 non-null  int64  \n",
      " 1   Age                                                 73000 non-null  float64\n",
      " 2   Occupation_Accountant                               73000 non-null  int64  \n",
      " 3   Occupation_Architect                                73000 non-null  int64  \n",
      " 4   Occupation_Developer                                73000 non-null  int64  \n",
      " 5   Occupation_Doctor                                   73000 non-null  int64  \n",
      " 6   Occupation_Engineer                                 73000 non-null  int64  \n",
      " 7   Occupation_Entrepreneur                             73000 non-null  int64  \n",
      " 8   Occupation_Journalist                               73000 non-null  int64  \n",
      " 9   Occupation_Lawyer                                   73000 non-null  int64  \n",
      " 10  Occupation_Manager                                  73000 non-null  int64  \n",
      " 11  Occupation_Mechanic                                 73000 non-null  int64  \n",
      " 12  Occupation_Media_Manager                            73000 non-null  int64  \n",
      " 13  Occupation_Musician                                 73000 non-null  int64  \n",
      " 14  Occupation_Scientist                                73000 non-null  int64  \n",
      " 15  Occupation_Teacher                                  73000 non-null  int64  \n",
      " 16  Occupation_Writer                                   73000 non-null  int64  \n",
      " 17  Annual_Income                                       73000 non-null  float64\n",
      " 18  Monthly_Inhand_Salary                               73000 non-null  float64\n",
      " 19  Num_Bank_Accounts                                   73000 non-null  float64\n",
      " 20  Num_Credit_Card                                     73000 non-null  float64\n",
      " 21  Interest_Rate                                       73000 non-null  float64\n",
      " 22  Num_of_Loan                                         73000 non-null  float64\n",
      " 23  Credit_Mix_Bad                                      73000 non-null  int64  \n",
      " 24  Credit_Mix_Good                                     73000 non-null  int64  \n",
      " 25  Credit_Mix_Standard                                 73000 non-null  int64  \n",
      " 26  has_No_Data_loan                                    73000 non-null  int64  \n",
      " 27  Payment_of_Min_Amount_NM                            73000 non-null  int64  \n",
      " 28  Payment_of_Min_Amount_No                            73000 non-null  int64  \n",
      " 29  Payment_of_Min_Amount_Yes                           73000 non-null  int64  \n",
      " 30  Payment_Behaviour_High_spent_Large_value_payments   73000 non-null  int64  \n",
      " 31  Payment_Behaviour_High_spent_Medium_value_payments  73000 non-null  int64  \n",
      " 32  Payment_Behaviour_High_spent_Small_value_payments   73000 non-null  int64  \n",
      " 33  Payment_Behaviour_Low_spent_Large_value_payments    73000 non-null  int64  \n",
      " 34  Payment_Behaviour_Low_spent_Medium_value_payments   73000 non-null  int64  \n",
      " 35  Payment_Behaviour_Low_spent_Small_value_payments    73000 non-null  int64  \n",
      " 36  has_not_specified_loan                              73000 non-null  int64  \n",
      " 37  has_credit_builder_loan                             73000 non-null  int64  \n",
      " 38  has_personal_loan                                   73000 non-null  int64  \n",
      " 39  has_debt_consolidation_loan                         73000 non-null  int64  \n",
      " 40  has_student_loan                                    73000 non-null  int64  \n",
      " 41  has_payday_loan                                     73000 non-null  int64  \n",
      " 42  has_mortgage_loan                                   73000 non-null  int64  \n",
      " 43  has_auto_loan                                       73000 non-null  int64  \n",
      " 44  has_home_equity_loan                                73000 non-null  int64  \n",
      " 45  Delay_from_due_date                                 73000 non-null  float64\n",
      " 46  Num_of_Delayed_Payment                              73000 non-null  float64\n",
      " 47  Changed_Credit_Limit                                73000 non-null  float64\n",
      " 48  Num_Credit_Inquiries                                73000 non-null  float64\n",
      " 49  Outstanding_Debt                                    73000 non-null  float64\n",
      " 50  Credit_Utilization_Ratio                            73000 non-null  float64\n",
      " 51  Credit_History_Age                                  73000 non-null  float64\n",
      " 52  Total_EMI_per_month                                 73000 non-null  float64\n",
      " 53  Amount_invested_monthly                             73000 non-null  float64\n",
      " 54  Monthly_Balance                                     73000 non-null  float64\n",
      " 55  Credit_Score                                        73000 non-null  object \n",
      "dtypes: float64(17), int64(38), object(1)\n",
      "memory usage: 31.2+ MB\n",
      "None\n",
      "========== Dataset: Credit Score synth balanced ==========\n",
      "Softmax selfmade:\n",
      "Accuracy on test: 0.6871232876712329\n",
      "Accuracy on train: 0.6863796477495108\n",
      "Confusion matrix: \n",
      "[[5962  179 1068]\n",
      " [1169 4559 1383]\n",
      " [1561 1492 4527]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.69      0.83      0.75      7209\n",
      "        Poor       0.73      0.64      0.68      7111\n",
      "    Standard       0.65      0.60      0.62      7580\n",
      "\n",
      "    accuracy                           0.69     21900\n",
      "   macro avg       0.69      0.69      0.69     21900\n",
      "weighted avg       0.69      0.69      0.68     21900\n",
      "\n",
      "\n",
      "Softmax library:\n",
      "Accuracy on test: 0.6271232876712329\n",
      "Accuracy on train: 0.6298434442270059\n",
      "Confusion matrix: \n",
      "[[5636  256 1317]\n",
      " [1119 5109  883]\n",
      " [2810 1781 2989]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.59      0.78      0.67      7209\n",
      "        Poor       0.71      0.72      0.72      7111\n",
      "    Standard       0.58      0.39      0.47      7580\n",
      "\n",
      "    accuracy                           0.63     21900\n",
      "   macro avg       0.63      0.63      0.62     21900\n",
      "weighted avg       0.63      0.63      0.62     21900\n",
      "\n",
      "\n",
      "Decision Tree selfmade:\n",
      "Accuracy on test: 0.7393150684931507\n",
      "Accuracy on train: 0.8381604696673189\n",
      "Confusion matrix: \n",
      "[[5667  294 1248]\n",
      " [ 293 5483 1335]\n",
      " [1133 1406 5041]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.80      0.79      0.79      7209\n",
      "        Poor       0.76      0.77      0.77      7111\n",
      "    Standard       0.66      0.67      0.66      7580\n",
      "\n",
      "    accuracy                           0.74     21900\n",
      "   macro avg       0.74      0.74      0.74     21900\n",
      "weighted avg       0.74      0.74      0.74     21900\n",
      "\n",
      "\n",
      "Decision Tree library:\n",
      "Accuracy on test: 0.7559817351598174\n",
      "Accuracy on train: 0.8559491193737769\n",
      "Confusion matrix: \n",
      "[[5764  225 1220]\n",
      " [ 328 5734 1049]\n",
      " [1113 1409 5058]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.80      0.80      0.80      7209\n",
      "        Poor       0.78      0.81      0.79      7111\n",
      "    Standard       0.69      0.67      0.68      7580\n",
      "\n",
      "    accuracy                           0.76     21900\n",
      "   macro avg       0.76      0.76      0.76     21900\n",
      "weighted avg       0.75      0.76      0.76     21900\n",
      "\n",
      "\n",
      "Random Forest library:\n",
      "Accuracy on test: 0.726027397260274\n",
      "Accuracy on train: 0.7288845401174169\n",
      "Confusion matrix: \n",
      "[[6084  146  979]\n",
      " [1036 5430  645]\n",
      " [1504 1690 4386]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.71      0.84      0.77      7209\n",
      "        Poor       0.75      0.76      0.76      7111\n",
      "    Standard       0.73      0.58      0.65      7580\n",
      "\n",
      "    accuracy                           0.73     21900\n",
      "   macro avg       0.73      0.73      0.72     21900\n",
      "weighted avg       0.73      0.73      0.72     21900\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение GBDT: 100%|██████████| 50/50 [01:23<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.757716894977169\n",
      "Accuracy on train: 0.7788649706457925\n",
      "Confusion matrix: \n",
      "[[6219  164  826]\n",
      " [ 811 5572  728]\n",
      " [1457 1320 4803]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.73      0.86      0.79      7209\n",
      "        Poor       0.79      0.78      0.79      7111\n",
      "    Standard       0.76      0.63      0.69      7580\n",
      "\n",
      "    accuracy                           0.76     21900\n",
      "   macro avg       0.76      0.76      0.76     21900\n",
      "weighted avg       0.76      0.76      0.75     21900\n",
      "\n",
      "\n",
      "Gradient Boosting Decision Trees library:\n",
      "Accuracy on test: 0.788675799086758\n",
      "Accuracy on train: 0.8720939334637965\n",
      "Confusion matrix: \n",
      "[[6376   93  740]\n",
      " [ 478 5809  824]\n",
      " [1240 1253 5087]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.79      0.88      0.83      7209\n",
      "        Poor       0.81      0.82      0.81      7111\n",
      "    Standard       0.76      0.67      0.71      7580\n",
      "\n",
      "    accuracy                           0.79     21900\n",
      "   macro avg       0.79      0.79      0.79     21900\n",
      "weighted avg       0.79      0.79      0.79     21900\n",
      "\n",
      "\n",
      "MLP selfmade:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0, loss=1.783977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  20%|██        | 200/1000 [01:52<07:14,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 200, loss=1.295207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  40%|████      | 400/1000 [03:42<05:23,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 400, loss=1.257108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение MLP:  53%|█████▎    | 531/1000 [04:49<04:15,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Остановка на 531 эпохе, change=9.98e-05<eps=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.6875342465753425\n",
      "Accuracy on train: 0.6925636007827789\n",
      "Confusion matrix: \n",
      "[[5906  219 1084]\n",
      " [1116 4821 1174]\n",
      " [1608 1642 4330]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.68      0.82      0.75      7209\n",
      "        Poor       0.72      0.68      0.70      7111\n",
      "    Standard       0.66      0.57      0.61      7580\n",
      "\n",
      "    accuracy                           0.69     21900\n",
      "   macro avg       0.69      0.69      0.69     21900\n",
      "weighted avg       0.69      0.69      0.68     21900\n",
      "\n",
      "\n",
      "MLP library:\n",
      "Accuracy on test: 0.7472602739726028\n",
      "Accuracy on train: 0.8352641878669276\n",
      "Confusion matrix: \n",
      "[[6234  236  739]\n",
      " [ 474 5632 1005]\n",
      " [1548 1533 4499]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.76      0.86      0.81      7209\n",
      "        Poor       0.76      0.79      0.78      7111\n",
      "    Standard       0.72      0.59      0.65      7580\n",
      "\n",
      "    accuracy                           0.75     21900\n",
      "   macro avg       0.75      0.75      0.74     21900\n",
      "weighted avg       0.75      0.75      0.74     21900\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
